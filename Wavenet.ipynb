{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4561ac1a",
   "metadata": {},
   "source": [
    "# Music Generation using Wavenet  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd12eb0",
   "metadata": {},
   "source": [
    "Importing the prerequisite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e440a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2901b314",
   "metadata": {},
   "source": [
    "Music 21 is a library or toolkit used for manipulation of midi files. A midi file consists of notes, chords, pitch, octave and offset. In our dataset, the offset is constant.We load each file into a Music21 object using converter.parse. This will parse the files and We will get a list of notes and chords. Using the Music21.PartitionByInstrument function, the file is broken up into individual instruments, if there are multiple instruments. We append the pitch of every note object using its string notation and every chord by encoding the id of every note in the chord. Now that we have put all the notes and chords into a sequential list, we create sequences that will work as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2cf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"loading :\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "\n",
    "    midi = converter.parse(file)\n",
    "\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            for element in notes_to_parse:\n",
    "\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4663b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997aa7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading : ../Dataset/schubert_D850_1.mid\n",
      "loading : ../Dataset/schubert_D850_2.mid\n",
      "loading : ../Dataset/schubert_D850_3.mid\n",
      "loading : ../Dataset/schubert_D850_4.mid\n",
      "loading : ../Dataset/schubert_D935_1.mid\n",
      "loading : ../Dataset/schubert_D935_2.mid\n",
      "loading : ../Dataset/schubert_D935_3.mid\n",
      "loading : ../Dataset/schubert_D935_4.mid\n",
      "loading : ../Dataset/schub_d760_1.mid\n",
      "loading : ../Dataset/schub_d760_2.mid\n",
      "loading : ../Dataset/schub_d760_3.mid\n",
      "loading : ../Dataset/schub_d760_4.mid\n",
      "loading : ../Dataset/schub_d960_1.mid\n",
      "loading : ../Dataset/schub_d960_2.mid\n",
      "loading : ../Dataset/schub_d960_3.mid\n",
      "loading : ../Dataset/schub_d960_4.mid\n",
      "loading : ../Dataset/schuim-1.mid\n",
      "loading : ../Dataset/schuim-2.mid\n",
      "loading : ../Dataset/schuim-3.mid\n",
      "loading : ../Dataset/schuim-4.mid\n",
      "loading : ../Dataset/schumm-1.mid\n",
      "loading : ../Dataset/schumm-2.mid\n",
      "loading : ../Dataset/schumm-3.mid\n",
      "loading : ../Dataset/schumm-4.mid\n",
      "loading : ../Dataset/schumm-5.mid\n",
      "loading : ../Dataset/schumm-6.mid\n",
      "loading : ../Dataset/schu_143_1.mid\n",
      "loading : ../Dataset/schu_143_2.mid\n",
      "loading : ../Dataset/schu_143_3.mid\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "path='../Dataset/'\n",
    "\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files],dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480b728",
   "metadata": {},
   "source": [
    "We find the number of unique notes in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0bd32a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "unique_notes = list(set(notes_))\n",
    "\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd6db9e",
   "metadata": {},
   "source": [
    "We compute the frequency of every note and visualize the frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34a150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([186.,  46.,  27.,  10.,   4.,   6.,   6.,  12.,   8.,   3.]),\n",
       " array([1.0000e+00, 1.7290e+02, 3.4480e+02, 5.1670e+02, 6.8860e+02,\n",
       "        8.6050e+02, 1.0324e+03, 1.2043e+03, 1.3762e+03, 1.5481e+03,\n",
       "        1.7200e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 324
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c71f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b428046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music,dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f24ef0",
   "metadata": {},
   "source": [
    "# Input and Output sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3763f71a",
   "metadata": {},
   "source": [
    "Creating input and output sequences where each step of input has first 100 notes and the output has the remaining notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "351f1f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 50\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c3baed",
   "metadata": {},
   "source": [
    "Neural networks work better with integers, so we can write a function which creates a dictionary which maps each note into an integer and then generate sequences which are the inputs and outputs of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c10c69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ede7b",
   "metadata": {},
   "source": [
    "preparing input sequences compatible with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a672d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd8006",
   "metadata": {},
   "source": [
    "preparing output sequences compatible with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16658adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716b7aa",
   "metadata": {},
   "source": [
    "Neural Network model creation and splitting of data to feed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9920da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58912e14",
   "metadata": {},
   "source": [
    "# Wavenet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bdfbba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 100)           17300     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 173)               44461     \n",
      "=================================================================\n",
      "Total params: 270,081\n",
      "Trainable params: 270,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import (Dense,\n",
    "                            Flatten,Conv1D,Embedding,MaxPool1D,Dropout,GlobalMaxPool1D)\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    " \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a4a8772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 32) for input Tensor(\"embedding_input:0\", shape=(None, 32), dtype=float32), but it was called on an input with incompatible shape (None, 50).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 32) for input Tensor(\"embedding_input:0\", shape=(None, 32), dtype=float32), but it was called on an input with incompatible shape (None, 50).\n",
      "499/500 [============================>.] - ETA: 0s - loss: 4.3101 - acc: 0.0591WARNING:tensorflow:Model was constructed with shape (None, 32) for input Tensor(\"embedding_input:0\", shape=(None, 32), dtype=float32), but it was called on an input with incompatible shape (None, 50).\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 4.3100 - acc: 0.0591 - val_loss: 4.0429 - val_acc: 0.0941\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 70s 141ms/step - loss: 3.8362 - acc: 0.1069 - val_loss: 3.8696 - val_acc: 0.1185\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 71s 143ms/step - loss: 3.6650 - acc: 0.1282 - val_loss: 3.7368 - val_acc: 0.1413\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 3.5303 - acc: 0.1438 - val_loss: 3.6300 - val_acc: 0.1486\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 3.4278 - acc: 0.1548 - val_loss: 3.5439 - val_acc: 0.1606\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 3.3414 - acc: 0.1646 - val_loss: 3.4620 - val_acc: 0.1634\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 3.2643 - acc: 0.1757 - val_loss: 3.4526 - val_acc: 0.1699\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 71s 141ms/step - loss: 3.1955 - acc: 0.1813 - val_loss: 3.3870 - val_acc: 0.1755\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 3.1361 - acc: 0.1896 - val_loss: 3.3159 - val_acc: 0.1780\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 66s 131ms/step - loss: 3.0828 - acc: 0.1944 - val_loss: 3.2929 - val_acc: 0.1835\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 3.0357 - acc: 0.2016 - val_loss: 3.2570 - val_acc: 0.1857\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 2.9897 - acc: 0.2047 - val_loss: 3.2408 - val_acc: 0.1924\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 69s 139ms/step - loss: 2.9537 - acc: 0.2125 - val_loss: 3.2077 - val_acc: 0.1969\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 68s 135ms/step - loss: 2.9154 - acc: 0.2198 - val_loss: 3.1714 - val_acc: 0.1962\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 67s 135ms/step - loss: 2.8796 - acc: 0.2237 - val_loss: 3.1485 - val_acc: 0.1965\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 70s 139ms/step - loss: 2.8517 - acc: 0.2262 - val_loss: 3.1319 - val_acc: 0.1996\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 68s 135ms/step - loss: 2.8197 - acc: 0.2331 - val_loss: 3.1206 - val_acc: 0.2021\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 2.7947 - acc: 0.2348 - val_loss: 3.0875 - val_acc: 0.2062\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 2.7681 - acc: 0.2395 - val_loss: 3.0751 - val_acc: 0.2065\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 70s 139ms/step - loss: 2.7505 - acc: 0.2414 - val_loss: 3.0624 - val_acc: 0.2068\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 68s 137ms/step - loss: 2.7300 - acc: 0.2464 - val_loss: 3.0571 - val_acc: 0.2142\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 68s 137ms/step - loss: 2.7058 - acc: 0.2475 - val_loss: 3.0378 - val_acc: 0.2157\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 2.6816 - acc: 0.2527 - val_loss: 3.0203 - val_acc: 0.2158\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 2.6758 - acc: 0.2529 - val_loss: 3.0150 - val_acc: 0.2215\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 69s 138ms/step - loss: 2.6569 - acc: 0.2560 - val_loss: 3.0062 - val_acc: 0.2193\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 69s 138ms/step - loss: 2.6463 - acc: 0.2582 - val_loss: 2.9886 - val_acc: 0.2224\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 2.6243 - acc: 0.2619 - val_loss: 2.9927 - val_acc: 0.2202\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 67s 135ms/step - loss: 2.6125 - acc: 0.2629 - val_loss: 2.9761 - val_acc: 0.2227\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 2.6016 - acc: 0.2657 - val_loss: 2.9785 - val_acc: 0.2207\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 68s 136ms/step - loss: 2.5830 - acc: 0.2690 - val_loss: 2.9560 - val_acc: 0.2257\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 71s 142ms/step - loss: 2.5759 - acc: 0.2700 - val_loss: 2.9611 - val_acc: 0.2254\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 67s 133ms/step - loss: 2.5655 - acc: 0.2717 - val_loss: 2.9390 - val_acc: 0.2244\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 67s 133ms/step - loss: 2.5542 - acc: 0.2747 - val_loss: 2.9490 - val_acc: 0.2289\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 2.5390 - acc: 0.2767 - val_loss: 2.9325 - val_acc: 0.2336\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 73s 147ms/step - loss: 2.5400 - acc: 0.2761 - val_loss: 2.9268 - val_acc: 0.2343\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 64s 129ms/step - loss: 2.5240 - acc: 0.2802 - val_loss: 2.9075 - val_acc: 0.2296\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 70s 139ms/step - loss: 2.5090 - acc: 0.2822 - val_loss: 2.9074 - val_acc: 0.2324\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 2.5025 - acc: 0.2829 - val_loss: 2.9051 - val_acc: 0.2342\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 2.4979 - acc: 0.2840 - val_loss: 2.8968 - val_acc: 0.2338\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 2.4867 - acc: 0.2848 - val_loss: 2.8908 - val_acc: 0.2374\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 2.4852 - acc: 0.2886 - val_loss: 2.8879 - val_acc: 0.2381\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 2.4827 - acc: 0.2854 - val_loss: 2.9086 - val_acc: 0.2341\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 2.4617 - acc: 0.2900 - val_loss: 2.8890 - val_acc: 0.2392\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 2.4613 - acc: 0.2862 - val_loss: 2.8935 - val_acc: 0.2362\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 2.4589 - acc: 0.2880 - val_loss: 2.8699 - val_acc: 0.2415\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 2.4487 - acc: 0.2915 - val_loss: 2.8771 - val_acc: 0.2377\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 2.4376 - acc: 0.2928 - val_loss: 2.8654 - val_acc: 0.2405\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 2.4357 - acc: 0.2945 - val_loss: 2.8568 - val_acc: 0.2461\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 2.4251 - acc: 0.2977 - val_loss: 2.8688 - val_acc: 0.2448\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 2.4315 - acc: 0.2943 - val_loss: 2.8626 - val_acc: 0.2408\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880afd65",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f911b",
   "metadata": {},
   "source": [
    "To generate new samples, we select a random array of sample values as a starting point to model and when the model outputs the probability distribution over all the samples, we choose the value with the maximum probability and append it to an array of samples.We then delete the first element and pass as an input for the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3281650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 32) for input Tensor(\"embedding_input:0\", shape=(None, 32), dtype=float32), but it was called on an input with incompatible shape (None, 50).\n",
      "[81, 75, 17, 17, 75, 17, 28, 17, 17, 28]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76e11aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 42, 114,   3,  81,  67,  63,  81, 101, 101, 166,  81, 101,  17,\n",
       "        17, 101,  17,  28,  28,  17,  28,  47,  47,  28,  47,  42, 114,\n",
       "         3, 171, 166,  66,  66,  63, 158, 105,  63,  81,  81,  49,  63,\n",
       "        81,  81,  75,  17,  17,  75,  17,  28,  17,  17,  28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9639ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c5ae7e",
   "metadata": {},
   "source": [
    "Next, we will loop through the predicted output and treat chords and notes separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d0d3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='musics.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a0e9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a0638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
